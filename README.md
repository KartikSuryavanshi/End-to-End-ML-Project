ğŸ“˜ End-to-End Machine Learning Project: Student Marks Prediction

This project demonstrates an end-to-end machine learning pipeline that predicts student marks based on study hours.
It includes everything from data ingestion â†’ model training â†’ deployment â†’ CI/CD on AWS using:

GitHub

AWS CodePipeline

AWS Elastic Beanstalk

ğŸš€ Project Architecture
GitHub Repository â†’ CodePipeline â†’ Elastic Beanstalk â†’ Live ML App

ğŸ§  Tech Stack
Machine Learning

Python

Pandas, NumPy

Scikit-Learn

Pickle for model serialization

Backend

Flask

AWS Deployment

AWS CodePipeline (CI/CD)

AWS CodeBuild (optional)

AWS Elastic Beanstalk

AWS S3

ğŸ—‚ Project Structure
ML-Projects/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ student.csv
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py
â”‚   â”‚   â”œâ”€â”€ data_transformation.py
â”‚   â”‚   â”œâ”€â”€ model_trainer.py
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â”œâ”€â”€ training_pipeline.py
â”‚   â”‚   â””â”€â”€ prediction_pipeline.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â”œâ”€â”€ exception.py
â”‚   â””â”€â”€ logger.py
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html
â”œâ”€â”€ application.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

ğŸ¤– ML Pipeline Workflow
1ï¸âƒ£ Data Ingestion

Loads dataset

Splits into train/test

Stores processed data

2ï¸âƒ£ Data Transformation

Feature scaling

Missing value handling

Saves preprocessing pipeline

3ï¸âƒ£ Model Training

Trains multiple ML models

Selects best model based on accuracy

Exports model as model.pkl

4ï¸âƒ£ Prediction Pipeline

Loads trained model

Accepts input features

Produces predicted marks

ğŸŒ Deployment Workflow (CI/CD on AWS)
1. Developer pushes code â†’ GitHub

Triggers AWS CodePipeline automatically.

2. AWS CodePipeline

Pulls latest code

Builds package

Sends to Elastic Beanstalk

3. Elastic Beanstalk

Hosts ML web application

Serves prediction model

ğŸ›  Run Locally
1. Clone repository
git clone https://github.com/KartikSuryavanshi/ML-Projects.git
cd ML-Projects

2. Create virtual environment
conda create -n mlproject python=3.8 -y
conda activate mlproject

3. Install dependencies
pip install -r requirements.txt

4. Start application
python application.py

ğŸ— Deploy on AWS Elastic Beanstalk
Initialize EB project
eb init

Create environment
eb create ml-env

Deploy
eb deploy

ğŸ“¬ API Endpoints
Method	Endpoint	Description
GET	/	Homepage
POST	/predict	Predicts student marks
ğŸ”§ Future Enhancements

Add Docker support

Hyperparameter tuning

Model monitoring

CloudWatch logging integration

ğŸ‘¨â€ğŸ’» Author

Kartik Suryavanshi
GitHub: https://github.com/KartikSuryavanshi

â­ If you find this project useful, please star the repository! â­
